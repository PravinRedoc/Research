{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fCgMNEvI4Zxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ANUNIqCe4Zxn"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.25, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "h43kDT3M41u5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can write your code here\n",
    "clf = SVC(gamma=0.001, C=100.)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = clf.dual_coef_\n",
    "b  = clf._intercept_\n",
    "sv = clf.support_vectors_\n",
    "gamma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_rbf(point,j,sv):\n",
    "    norm2 = np.linalg.norm(sv[j]-point)\n",
    "    k = np.exp(-gamma*(norm2**2))\n",
    "    return k\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_function(X,a,b,sv):\n",
    "    decision_output = []\n",
    "    dual_coefs = a[0]\n",
    "    for point in X:\n",
    "        decision_made = 0\n",
    "        for j in range(np.shape(sv)[0]):\n",
    "            #norm2 = np.linalg.norm(sv[j]-point) \n",
    "            \n",
    "            decision_made=decision_made + dual_coefs[j] *  K_rbf(point,j,sv) \n",
    "        decision_made = (decision_made- b)[0]      \n",
    "        decision_output.append(decision_made)\n",
    "    return np.array(decision_output)\n",
    "    \n",
    "                                           \n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.76443341, -2.41851071, -1.76821112, -2.69688212, -2.49742518,\n",
       "       -2.80311655, -1.78074948, -2.14381409, -2.15336257,  1.73311625])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_cv = decision_function(X_cv,a,b,sv)\n",
    "decision_cv[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.76443341, -2.41851071, -1.76821112, -2.69688212, -2.49742518,\n",
       "       -2.80311655, -1.78074948, -2.14381409, -2.15336257,  1.73311625])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_sklearn =clf.decision_function(X_cv)\n",
    "decision_sklearn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/28503932/calculating-decision-function-of-svm-manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_test = decision_function(X_test,a,b,sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(908, 2092)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Np,Nm = len(y_train[y_train==1]),len(y_train[y_train==0]) #modified to train(rectified)\n",
    "Np,Nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(908, 2092)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Np,Nm =  (y_train==1).sum(),(y_train==0).sum()\n",
    "Np,Nm # N+ and N-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv_real = np.array([(Np+1)/(Np+2) if x==1 else 1/(Nm+2) for x in y_cv ]) #modifying y_cv to change it to real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(y_cv_real, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.77554919e-04, 9.98901099e-01]), array([697, 303], dtype=int64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements, counts_elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    loss=0\n",
    "    for i in range(len(y_true)):\n",
    "        loss+=((y_true[i]*np.log10(y_pred[i]))+((1-y_true[i])*np.log10((1-y_pred[i]))))\n",
    "        \n",
    "    loss =(-1*loss)/len(y_true)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss:  0.2596166100777763\n",
      "Epoch: 1\n",
      "Train loss:  0.2290371142276691\n",
      "Epoch: 2\n",
      "Train loss:  0.2060636799229681\n",
      "Epoch: 3\n",
      "Train loss:  0.18843448358573914\n",
      "Epoch: 4\n",
      "Train loss:  0.17461286084938965\n",
      "Epoch: 5\n",
      "Train loss:  0.16355725961646134\n",
      "Epoch: 6\n",
      "Train loss:  0.15455347420680648\n",
      "Epoch: 7\n",
      "Train loss:  0.1471030276331263\n",
      "Epoch: 8\n",
      "Train loss:  0.1408510828307992\n",
      "Epoch: 9\n",
      "Train loss:  0.13554001356896733\n",
      "Epoch: 10\n",
      "Train loss:  0.13097921300200227\n",
      "Epoch: 11\n",
      "Train loss:  0.1270251599929128\n",
      "Epoch: 12\n",
      "Train loss:  0.12356802611682541\n",
      "Epoch: 13\n",
      "Train loss:  0.12052251371488411\n",
      "Epoch: 14\n",
      "Train loss:  0.11782147662678476\n",
      "Epoch: 15\n",
      "Train loss:  0.1154114027370653\n",
      "Epoch: 16\n",
      "Train loss:  0.11324916355190255\n",
      "Epoch: 17\n",
      "Train loss:  0.11129964028133127\n",
      "Epoch: 18\n",
      "Train loss:  0.10953396579369408\n",
      "Epoch: 19\n",
      "Train loss:  0.10792820571883352\n",
      "Epoch: 20\n",
      "Train loss:  0.1064623570396962\n",
      "Epoch: 21\n",
      "Train loss:  0.10511957920337044\n",
      "Epoch: 22\n",
      "Train loss:  0.10388559759499964\n",
      "Epoch: 23\n",
      "Train loss:  0.1027482362351436\n",
      "Epoch: 24\n",
      "Train loss:  0.1016970483890391\n",
      "Epoch: 25\n",
      "Train loss:  0.10072302210195892\n",
      "Epoch: 26\n",
      "Train loss:  0.09981834360590686\n",
      "Epoch: 27\n",
      "Train loss:  0.09897620581601885\n",
      "Epoch: 28\n",
      "Train loss:  0.0981906522466751\n",
      "Epoch: 29\n",
      "Train loss:  0.09745644896611846\n",
      "Epoch: 30\n",
      "Train loss:  0.09676897890800629\n",
      "Epoch: 31\n",
      "Train loss:  0.09612415413183865\n",
      "Epoch: 32\n",
      "Train loss:  0.09551834258661175\n",
      "Epoch: 33\n",
      "Train loss:  0.09494830666520213\n",
      "Epoch: 34\n",
      "Train loss:  0.0944111513997955\n",
      "Epoch: 35\n",
      "Train loss:  0.09390428058386552\n",
      "Epoch: 36\n",
      "Train loss:  0.09342535944501057\n",
      "Epoch: 37\n",
      "Train loss:  0.09297228275848683\n",
      "Epoch: 38\n",
      "Train loss:  0.09254314750064643\n",
      "Epoch: 39\n",
      "Train loss:  0.09213622930759165\n",
      "Epoch: 40\n",
      "Train loss:  0.09174996213683173\n",
      "Epoch: 41\n",
      "Train loss:  0.09138292063602074\n",
      "Epoch: 42\n",
      "Train loss:  0.09103380480850191\n",
      "Epoch: 43\n",
      "Train loss:  0.09070142663481552\n",
      "Epoch: 44\n",
      "Train loss:  0.09038469836580512\n",
      "Epoch: 45\n",
      "Train loss:  0.0900826222491666\n",
      "Epoch: 46\n",
      "Train loss:  0.08979428148920779\n",
      "Epoch: 47\n",
      "Train loss:  0.08951883227088146\n",
      "Epoch: 48\n",
      "Train loss:  0.0892554967050379\n",
      "Epoch: 49\n",
      "Train loss:  0.08900355657338184\n"
     ]
    }
   ],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''   \n",
    "    w= np.zeros_like(dim)\n",
    "    b=0\n",
    "    return w,b\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    \n",
    "    sig = 1/(1+np.exp(-z))\n",
    "    return sig\n",
    "\n",
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    dw0 = np.dot(w, x) + b\n",
    "    dw = x*(y - sigmoid(dw0)) - ((alpha/(N)) * w)\n",
    "    return dw\n",
    "def gradient_db(x,y,w,b):\n",
    "   '''In this function, we will compute gradient w.r.to b '''\n",
    "   db0 = np.dot(w, x) + b\n",
    "   db = y - sigmoid(db0)\n",
    "   return db\n",
    "   \n",
    "def find_proba(w,b, X):\n",
    "    \n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b       \n",
    "        predict.append(sigmoid(z))\n",
    "    return np.array(predict)\n",
    "   \n",
    "def train(X_train,y_train,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "    \n",
    "    w,b = initialize_weights(X_train[0]) \n",
    "    gw,gb = 0,0\n",
    "    trainloss_list = []\n",
    "    testloss_list = []\n",
    "    N = len(X_train)\n",
    "    for i in range(epochs):\n",
    "        \n",
    "        print(\"Epoch: \"+str(i))\n",
    "        \n",
    "        for i in range(N):\n",
    "            gw=gradient_dw(X_train[i],y_train[i],w,b,alpha,N)\n",
    "           \n",
    "            gb=gradient_db(X_train[i],y_train[i],w,b)\n",
    "           \n",
    "           \n",
    "            w=w+(eta0*gw)\n",
    "            b=b+(eta0*gb)\n",
    "        \n",
    "        \n",
    "        ytrain_pred = find_proba(w,b, X_train)\n",
    "        \n",
    "        losstr =logloss(y_train,ytrain_pred)\n",
    "        print(\"Train loss: \",losstr)\n",
    "        \n",
    "        trainloss_list.append(losstr)\n",
    "    \n",
    "        \n",
    "        \n",
    "    return w,b,trainloss_list\n",
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_cv)\n",
    "epochs=50\n",
    "w,b,trainloss_list=train(decision_cv,y_cv_real,epochs,alpha,eta0) #SGD on f_cv and y_cv_modified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(epochs),trainloss_list)\n",
    "\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.09859483,  0.15745993, -0.18882511, -2.43060079,  0.8270389 ,\n",
       "       -2.82150736, -2.26120895, -3.03068356, -4.10011678, -2.45545341,\n",
       "        1.82360666, -1.35025104, -2.57662381, -2.45166076, -2.23664788,\n",
       "       -1.97761124, -0.32465468,  3.04973076, -2.77280628, -3.40452629,\n",
       "       -1.52031542, -2.63825913, -4.18328145,  0.89401201, -2.68944977,\n",
       "       -2.6255718 , -2.83297529, -3.1358819 , -2.53671379, -0.32647612,\n",
       "       -3.66785681, -2.27444101, -0.62456175, -1.96098587, -1.08299093,\n",
       "       -3.03674687, -3.0883069 ,  3.20093489, -0.89075043, -2.04155068,\n",
       "        0.58323133,  2.1447849 , -2.6120149 ,  0.8441062 , -3.49024625,\n",
       "        2.37453505, -4.12379012, -2.41212015, -3.03648899, -3.49285601,\n",
       "       -3.07399418, -3.22873744, -1.21274132, -2.15619256, -3.50726994,\n",
       "       -0.92297137, -1.85545622, -2.88634775, -3.56635879, -1.84886796,\n",
       "       -2.43338317, -1.42028604, -2.76693454, -3.76134841,  0.12695645,\n",
       "       -3.24370601, -1.42292395,  1.96861955, -3.08763231,  0.69792683,\n",
       "       -2.06544121, -0.08585931, -0.68830817,  1.59369651,  0.01510182,\n",
       "       -1.68825364, -1.70019386,  1.80152675, -0.59614787, -1.76419881,\n",
       "       -3.2143871 , -1.15020193, -2.07758191,  1.80372066, -3.07423419,\n",
       "       -2.79580331, -0.90159726, -1.7860325 , -0.06009924,  0.86681213,\n",
       "        2.07462597, -1.92963856, -3.26156309,  1.45771645,  2.38777106,\n",
       "       -2.27001346, -2.75328072,  1.63286224,  0.83071513, -4.2054395 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pYgX = 1/(1+(np.exp(-1*((w*decision_test) + b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07184868, 0.52221448, 0.42129499, 0.04981921, 0.70572018,\n",
       "       0.03207765, 0.06011687, 0.02527186, 0.00733687, 0.04845659,\n",
       "       0.88535927, 0.15703877, 0.04230541, 0.04866223, 0.06176626,\n",
       "       0.08191149, 0.38299393, 0.97020261, 0.0339004 , 0.0164445 ,\n",
       "       0.13238842, 0.03946998, 0.00665919, 0.72177488, 0.03725442,\n",
       "       0.04003834, 0.03166242, 0.02240261, 0.04424419, 0.38248894,\n",
       "       0.01212593, 0.05924545, 0.30389679, 0.08339073, 0.2031389 ,\n",
       "       0.02509718, 0.02365851, 0.97492592, 0.24210188, 0.07644284,\n",
       "       0.64303746, 0.9184224 , 0.04065431, 0.70986258, 0.01489419,\n",
       "       0.93647692, 0.00713728, 0.05085593, 0.02510458, 0.01484932,\n",
       "       0.0240496 , 0.0201363 , 0.17960051, 0.06746957, 0.01460389,\n",
       "       0.23523158, 0.09335835, 0.02979738, 0.01363888, 0.09401483,\n",
       "       0.04966487, 0.14646295, 0.0341268 , 0.01087962, 0.5132768 ,\n",
       "       0.01979261, 0.14607638, 0.90153231, 0.0236768 , 0.67330486,\n",
       "       0.07448685, 0.45100124, 0.28830753, 0.85500199, 0.48047365,\n",
       "       0.11134411, 0.10996518, 0.88270292, 0.31099638, 0.10282628,\n",
       "       0.02047128, 0.19066969, 0.07351059, 0.88296923, 0.02404299,\n",
       "       0.03302755, 0.23977392, 0.10048646, 0.45849675, 0.71531971,\n",
       "       0.91203739, 0.08624604, 0.01939012, 0.83407771, 0.9373947 ,\n",
       "       0.05953571, 0.03465892, 0.86060763, 0.70661535, 0.00648937])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pYgX[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E&F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
